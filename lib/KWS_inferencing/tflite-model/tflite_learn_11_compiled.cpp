/* Generated by Edge Impulse
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 *
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
// Generated on: 09.08.2023 07:35:04

#include <stdio.h>
#include <stdlib.h>
#include "edge-impulse-sdk/tensorflow/lite/c/builtin_op_data.h"
#include "edge-impulse-sdk/tensorflow/lite/c/common.h"
#include "edge-impulse-sdk/tensorflow/lite/micro/micro_mutable_op_resolver.h"
#include "edge-impulse-sdk/porting/ei_classifier_porting.h"

#if EI_CLASSIFIER_PRINT_STATE
#if defined(__cplusplus) && EI_C_LINKAGE == 1
extern "C" {
    extern void ei_printf(const char *format, ...);
}
#else
extern void ei_printf(const char *format, ...);
#endif
#endif

#if defined __GNUC__
#define ALIGN(X) __attribute__((aligned(X)))
#elif defined _MSC_VER
#define ALIGN(X) __declspec(align(X))
#elif defined __TASKING__
#define ALIGN(X) __align(X)
#endif

#ifndef EI_MAX_SCRATCH_BUFFER_COUNT
#define EI_MAX_SCRATCH_BUFFER_COUNT 6
#endif // EI_MAX_SCRATCH_BUFFER_COUNT

#ifndef EI_MAX_OVERFLOW_BUFFER_COUNT
#define EI_MAX_OVERFLOW_BUFFER_COUNT 10
#endif // EI_MAX_OVERFLOW_BUFFER_COUNT

using namespace tflite;
using namespace tflite::ops;
using namespace tflite::ops::micro;

namespace {

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX) || defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
constexpr int kTensorArenaSize = 3376;
#else
constexpr int kTensorArenaSize = 2352;
#endif

#if defined(EI_CLASSIFIER_ALLOCATION_STATIC)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX)
#pragma Bss(".tensor_arena")
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16);
#pragma Bss()
#elif defined(EI_CLASSIFIER_ALLOCATION_STATIC_HIMAX_GNU)
uint8_t tensor_arena[kTensorArenaSize] ALIGN(16) __attribute__((section(".tensor_arena")));
#else
#define EI_CLASSIFIER_ALLOCATION_HEAP 1
uint8_t* tensor_arena = NULL;
#endif

static uint8_t* tensor_boundary;
static uint8_t* current_location;

template <int SZ, class T> struct TfArray {
  int sz; T elem[SZ];
};
enum used_operators_e {
  OP_RESHAPE, OP_CONV_2D, OP_MAX_POOL_2D, OP_FULLY_CONNECTED, OP_SOFTMAX,  OP_LAST
};
struct TensorInfo_t { // subset of TfLiteTensor used for initialization from constant memory
  TfLiteAllocationType allocation_type;
  TfLiteType type;
  void* data;
  TfLiteIntArray* dims;
  size_t bytes;
  TfLiteQuantization quantization;
};
struct NodeInfo_t { // subset of TfLiteNode used for initialization from constant memory
  struct TfLiteIntArray* inputs;
  struct TfLiteIntArray* outputs;
  void* builtin_data;
  used_operators_e used_op_index;
};

typedef struct {
  TfLiteTensor tensor;
  int16_t index;
} TfLiteTensorWithIndex;

typedef struct {
  TfLiteEvalTensor tensor;
  int16_t index;
} TfLiteEvalTensorWithIndex;

TfLiteContext ctx{};
static const int MAX_TFL_TENSOR_COUNT = 4;
static TfLiteTensorWithIndex tflTensors[MAX_TFL_TENSOR_COUNT];
static const int MAX_TFL_EVAL_COUNT = 4;
static TfLiteEvalTensorWithIndex tflEvalTensors[MAX_TFL_EVAL_COUNT];
TfLiteRegistration registrations[OP_LAST];
TfLiteNode tflNodes[15];

const TfArray<2, int> tensor_dimension0 = { 2, { 1,507 } };
const TfArray<1, float> quant0_scale = { 1, { 0.053833801299333572, } };
const TfArray<1, int> quant0_zero = { 1, { 1 } };
const TfLiteAffineQuantization quant0 = { (TfLiteFloatArray*)&quant0_scale, (TfLiteIntArray*)&quant0_zero, 0 };
const ALIGN(16) int32_t tensor_data1[4] = { 1, 1, 39, 13, };
const TfArray<1, int> tensor_dimension1 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data2[4] = { 1, 39, 1, 8, };
const TfArray<1, int> tensor_dimension2 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data3[4] = { 1, 1, 20, 8, };
const TfArray<1, int> tensor_dimension3 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data4[4] = { 1, 20, 1, 16, };
const TfArray<1, int> tensor_dimension4 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data5[4] = { 1, 1, 10, 16, };
const TfArray<1, int> tensor_dimension5 = { 1, { 4 } };
const ALIGN(16) int32_t tensor_data6[4] = { 1, 10, 1, 32, };
const TfArray<1, int> tensor_dimension6 = { 1, { 4 } };
const ALIGN(8) int32_t tensor_data7[2] = { -1, 160, };
const TfArray<1, int> tensor_dimension7 = { 1, { 2 } };
const ALIGN(16) int8_t tensor_data8[8*1*3*13] = { 
  /* [0][0][][] */ 36,13,-25,82,28,-94,-43,30,51,34,-17,49,15, 34,-55,-35,2,53,-4,-39,1,-30,7,-44,3,-6, -29,-65,-127,-28,27,23,-11,56,-5,34,-19,-5,-1, 
  /* [1][0][][] */ -69,-4,25,94,66,-67,-37,-49,-19,-36,48,55,6, -68,21,36,85,68,-26,41,34,37,43,101,2,17, -127,-35,66,80,78,-50,-38,27,17,-73,1,-21,-31, 
  /* [2][0][][] */ 107,-89,114,48,20,13,-89,-90,-83,-3,-17,-19,-15, -8,99,67,39,11,-95,-17,-61,-35,-10,-51,-7,46, -38,127,22,38,-4,-25,-49,2,-49,-74,59,-61,11, 
  /* [3][0][][] */ -44,127,32,0,-36,-114,-67,-68,-73,-10,59,8,14, 54,-48,-1,35,-11,-47,-4,-12,44,45,104,22,69, -68,-59,-34,-39,11,-64,8,10,-15,18,71,-17,8, 
  /* [4][0][][] */ -5,-38,-30,-85,-98,73,76,-16,-44,29,-2,6,28, 89,25,30,-48,-57,72,127,61,-80,-3,63,126,35, 58,-5,66,-44,-122,-108,-91,46,20,-103,-116,-7,55, 
  /* [5][0][][] */ -2,-39,4,-22,11,-33,-44,-2,-30,13,-45,8,-17, 30,24,111,-66,-6,-33,-35,-19,13,11,-45,7,34, 105,-87,127,23,66,-7,0,14,-3,-6,-28,-32,-39, 
  /* [6][0][][] */ -110,-53,10,10,-8,18,34,48,35,-1,74,-13,-16, -47,127,24,85,117,-37,-41,-52,-26,-20,2,36,-12, -97,-9,-47,-31,38,22,90,26,-5,-23,-13,10,15, 
  /* [7][0][][] */ -51,-81,-15,4,-13,-85,-23,-77,60,-44,13,28,-40, -127,-82,22,44,72,8,-36,30,39,-47,2,26,-6, -85,-119,-21,-15,53,0,-37,-8,-20,-9,4,16,-32, 
};
const TfArray<4, int> tensor_dimension8 = { 4, { 8,1,3,13 } };
const TfArray<8, float> quant8_scale = { 8, { 0.023214526474475861, 0.0253620445728302, 0.012880069203674793, 0.024074885994195938, 0.017033897340297699, 0.020740870386362076, 0.026599669829010963, 0.026087190955877304, } };
const TfArray<8, int> quant8_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant8 = { (TfLiteFloatArray*)&quant8_scale, (TfLiteIntArray*)&quant8_zero, 0 };
const ALIGN(16) int32_t tensor_data9[8] = { -944, -838, -5702, -1582, -3597, -3075, 1027, 83, };
const TfArray<1, int> tensor_dimension9 = { 1, { 8 } };
const TfArray<8, float> quant9_scale = { 8, { 0.0012497261632233858, 0.0013653353089466691, 0.00069338310277089477, 0.001296042581088841, 0.0009169994737021625, 0.0011165598407387733, 0.0014319613110274076, 0.0014043726259842515, } };
const TfArray<8, int> quant9_zero = { 8, { 0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant9 = { (TfLiteFloatArray*)&quant9_scale, (TfLiteIntArray*)&quant9_zero, 0 };
const ALIGN(16) int8_t tensor_data10[16*1*3*8] = { 
  /* [0][0][][] */ 7,-127,67,37,-13,-4,30,-90, -49,-48,-45,-44,-35,32,27,-5, -40,2,-64,-41,-74,6,-126,-9, 
  /* [1][0][][] */ -6,-99,-14,-1,-61,-93,15,-63, -36,-44,-69,-118,-19,-51,-37,-127, -56,-56,-86,-50,-105,-111,-45,-108, 
  /* [2][0][][] */ 43,-28,0,9,-88,44,-11,-8, -34,-89,-31,2,-107,6,-72,-58, -43,-97,-74,-52,-28,-26,-39,-127, 
  /* [3][0][][] */ -5,6,-55,-44,-19,43,-113,-50, -4,27,-56,-64,-53,-18,-41,34, -13,-63,47,-14,-39,-77,-127,-22, 
  /* [4][0][][] */ -22,-64,-84,-55,-127,11,-78,-50, 6,-72,-62,-60,-58,-23,-110,-85, -51,-24,-121,-96,-73,-34,-49,-93, 
  /* [5][0][][] */ -8,-32,-49,-47,-69,-76,-38,-127, -37,-12,-54,-53,-21,-1,-38,-119, -39,-48,-25,-59,-28,-8,-49,-17, 
  /* [6][0][][] */ 22,-24,46,-3,-106,8,-127,-112, 79,-125,-9,37,-87,-66,-22,-73, -26,-84,30,-94,8,-19,-73,-110, 
  /* [7][0][][] */ -54,-63,0,-1,36,-50,-80,-80, -39,-55,-41,-46,-37,-44,-63,-63, -30,-54,-99,-20,-127,-50,1,4, 
  /* [8][0][][] */ -33,-65,-26,-44,-21,-57,16,-115, -50,-38,-40,-82,-34,-61,17,-127, -26,-33,-53,-58,-47,-49,-32,-91, 
  /* [9][0][][] */ -96,-114,-21,-27,21,-127,-27,-65, -81,-33,0,-3,-79,-66,-40,-57, 16,-9,42,-75,-19,-5,-69,-49, 
  /* [10][0][][] */ -40,-21,-14,8,2,-65,-18,-79, -92,-57,-65,-30,-14,-20,-45,-127, -79,-45,-98,-50,-23,-83,-71,-72, 
  /* [11][0][][] */ -7,-63,-43,-76,-75,-45,-28,-100, -55,-99,-25,-59,-28,-85,-127,-46, 12,-64,22,-16,-42,-76,-11,-32, 
  /* [12][0][][] */ -55,-63,-41,-51,17,-81,-108,-111, -10,-47,-15,-17,-47,-67,-63,-127, -49,-55,3,-25,-92,-17,-116,-102, 
  /* [13][0][][] */ -28,-66,-94,28,-54,-1,79,-50, -25,-31,-101,-37,-72,70,-34,5, -37,-78,-66,29,-66,-46,53,-127, 
  /* [14][0][][] */ -18,-23,-66,-45,-109,-25,-12,-42, -50,4,-42,-32,-127,-29,-29,-49, -18,12,-58,-18,-84,-34,-58,-51, 
  /* [15][0][][] */ 5,-117,-105,20,-20,-127,-93,-75, -60,-68,-37,-63,-46,-3,51,-105, -38,-75,-34,-96,-58,-121,-103,-63, 
};
const TfArray<4, int> tensor_dimension10 = { 4, { 16,1,3,8 } };
const TfArray<16, float> quant10_scale = { 16, { 0.026295801624655724, 0.023436166346073151, 0.019278205931186676, 0.036586783826351166, 0.023444142192602158, 0.032398253679275513, 0.019218768924474716, 0.030806053429841995, 0.020709574222564697, 0.021461613476276398, 0.0099403159692883492, 0.026216669008135796, 0.019314317032694817, 0.016199449077248573, 0.037569902837276459, 0.0095329741016030312, } };
const TfArray<16, int> quant10_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant10 = { (TfLiteFloatArray*)&quant10_scale, (TfLiteIntArray*)&quant10_zero, 0 };
const ALIGN(16) int32_t tensor_data11[16] = { 66, -176, -59, -197, -262, -244, -177, -241, -30, 73, -193, -178, -239, -71, -104, -129, };
const TfArray<1, int> tensor_dimension11 = { 1, { 16 } };
const TfArray<16, float> quant11_scale = { 16, { 0.0060661290772259235, 0.0054064453579485416, 0.0044472529552876949, 0.0084401369094848633, 0.0054082851856946945, 0.0074738925322890282, 0.0044335415586829185, 0.0071065905503928661, 0.0047774529084563255, 0.0049509392119944096, 0.0022931129205971956, 0.0060478742234408855, 0.0044555836357176304, 0.0037370205391198397, 0.0086669307202100754, 0.0021991438698023558, } };
const TfArray<16, int> quant11_zero = { 16, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant11 = { (TfLiteFloatArray*)&quant11_scale, (TfLiteIntArray*)&quant11_zero, 0 };
const ALIGN(16) int8_t tensor_data12[32*1*3*16] = { 
  /* [0][0][][] */ -64,64,-109,-71,64,28,-101,-78,-47,-30,-25,-106,-30,-95,-13,18, -63,-32,-118,-64,-51,-52,-102,-65,-49,-36,-7,-121,-34,-65,-54,17, -13,-32,-59,-103,-60,-103,-55,-127,-24,-108,-3,-92,-39,-24,-3,-1, 
  /* [1][0][][] */ -94,-81,-23,-115,-6,-73,-65,-68,-50,-123,-5,-69,-95,-53,-102,-8, -66,-83,2,-110,-37,4,-122,-103,-47,-127,-11,-91,25,-73,-78,21, -59,-27,-16,-29,-61,-57,-86,-88,-30,-127,-9,-83,6,-25,-70,-15, 
  /* [2][0][][] */ -44,-38,-91,-22,-23,-13,-92,-28,6,-23,9,7,-19,-43,-30,-4, -22,-6,-127,-38,10,-37,-37,-14,-6,-40,6,2,-14,-80,-12,-18, -70,-21,-40,-17,16,-24,-4,-48,-13,-23,1,-103,16,-77,-33,-15, 
  /* [3][0][][] */ 8,-46,-9,-66,-70,-10,-32,10,-41,-127,-9,-90,-62,-116,-9,2, -107,-61,29,-76,-73,-11,4,-47,-53,-13,-31,-90,-87,-120,-41,-38, -31,-27,-67,-77,-80,-42,28,-49,-56,30,0,-59,-7,-70,-11,-33, 
  /* [4][0][][] */ -42,15,-4,-36,21,-30,-111,-8,-36,-97,-26,-68,-28,-3,13,-11, -86,-47,-33,-5,-63,-1,-114,-45,-6,-52,17,-86,-21,-6,5,-53, -108,-36,-17,-42,-85,-27,-35,-37,-2,-62,21,-127,20,-6,-4,-37, 
  /* [5][0][][] */ -32,14,-56,-16,-70,-52,-51,-71,-25,-72,4,-66,-5,-4,-33,8, -27,-24,-44,-51,-44,-50,-21,-19,-43,-82,-6,-59,-11,-69,-18,7, -83,-21,-26,-127,-7,-23,-2,-1,-31,-92,-20,-52,-33,-67,-33,-19, 
  /* [6][0][][] */ -35,-42,-42,-18,-27,16,-127,-77,-15,-89,12,4,-45,-20,-20,10, -66,-36,-46,-10,-18,-1,-20,-11,-21,-62,-14,-13,-73,-32,-38,-14, -6,-65,-30,-22,2,-43,-27,-1,-14,-12,2,-49,-69,-14,-42,-23, 
  /* [7][0][][] */ -65,-82,-7,-51,-93,-68,-36,2,22,-54,2,-68,-1,-12,-54,20, -70,-38,-29,-13,-89,-78,-49,-36,6,-79,-5,-104,-22,-3,-33,-5, -57,-40,-10,-21,-127,-78,-6,-50,-36,-26,0,-64,0,-18,-10,-24, 
  /* [8][0][][] */ -27,-25,-18,-63,-36,-16,-12,-3,16,-41,-22,-59,-8,-16,30,-7, -19,-5,-19,-35,-47,-8,-39,-27,6,-46,-19,-127,16,-6,-3,-3, -52,-70,-23,-34,-37,-9,-20,-46,6,-54,-2,-35,-7,-10,-2,-10, 
  /* [9][0][][] */ 15,-45,-127,20,-66,-19,-27,-35,-9,-43,7,-55,-46,-111,-41,-31, -77,-64,-49,-51,-50,-52,-48,-77,-10,-61,37,-58,-33,-119,4,-45, -64,-94,-47,-69,-33,-83,-42,-10,20,-34,1,25,-44,-59,-14,-32, 
  /* [10][0][][] */ -117,-93,-10,-61,-56,-30,-122,-43,-3,-92,-2,-63,-58,-9,-41,21, -105,55,-25,-113,-93,-69,-127,-57,6,-6,-7,-54,59,-44,-71,-15, -113,-43,-8,-100,-90,-84,-52,-75,-21,-59,16,-20,63,-12,-53,-35, 
  /* [11][0][][] */ -60,35,-51,5,-32,-4,-91,-69,-35,-48,-34,24,-46,-18,3,-19, -65,-93,-53,86,-100,1,-32,-68,-71,-37,-31,-127,-26,17,-34,38, -86,-36,23,-21,99,75,-58,-27,-32,-57,-47,-88,-65,-17,-60,11, 
  /* [12][0][][] */ -22,-1,-93,-58,-12,-26,-17,-14,8,-36,-5,-2,4,-25,28,-19, -44,11,-23,-74,35,50,-20,-51,11,-47,-3,-2,19,-25,0,-23, -27,6,-22,-13,-20,10,-36,-3,1,-127,9,-13,7,-11,20,-23, 
  /* [13][0][][] */ -80,-45,-49,-62,-29,-87,-62,-54,-1,-36,40,-127,-22,-31,-21,-28, -99,-40,5,-40,-39,-50,-37,-15,-22,-59,39,-67,-21,-26,-50,-19, -80,-93,-37,-41,-17,-47,-25,-52,-16,-25,29,-66,-71,-73,-69,11, 
  /* [14][0][][] */ -24,-70,-103,-65,-78,-70,-75,-57,-15,-88,-76,-71,-39,-40,-33,-77, -21,-17,-19,-27,-36,-17,-97,-64,-92,-127,-59,-88,-62,-26,-53,-44, -15,-70,1,-17,-80,-38,-12,-61,-8,-93,-56,-109,-78,-27,-6,-35, 
  /* [15][0][][] */ -29,-49,-28,-54,5,-26,-27,-29,22,-22,-9,-127,-17,0,-19,-4, -17,-7,-39,-44,-26,-15,-55,-34,-19,-64,-25,-82,-26,-30,2,-30, -36,17,-26,-37,-38,-3,-29,-23,-18,-46,-34,-32,-4,-45,-3,-32, 
  /* [16][0][][] */ -37,-22,-12,-21,5,-20,-30,-18,18,-26,-12,-15,-14,-10,-25,-9, -24,-16,3,-25,5,-23,-10,-48,28,-38,9,-127,-16,-19,-15,-4, -14,-18,-17,-9,-6,-17,-17,-12,17,-7,19,-85,-15,-10,-17,1, 
  /* [17][0][][] */ 1,4,-32,-20,-51,-10,0,-21,0,-108,5,-25,-27,-38,-36,-27, -127,-21,-20,-28,-25,-30,-7,-24,9,-121,12,-51,-11,-7,-11,-14, -71,-122,-96,-29,-40,-44,3,-55,1,-10,-3,-74,-100,-11,-55,-16, 
  /* [18][0][][] */ -43,12,-49,-40,-10,-11,-127,-22,-1,-31,-7,-72,-18,-24,10,9, -18,38,-58,-71,29,-2,-60,-24,4,-13,-8,-48,3,-11,-15,1, -23,58,-63,2,39,34,-26,-2,-2,-32,-3,-56,5,-27,-14,4, 
  /* [19][0][][] */ -47,-43,-60,-29,12,-9,-8,-14,-14,-59,-3,-75,-4,-10,-2,-12, -4,-56,-15,7,-27,-35,-13,-1,-14,-17,-5,-109,-12,-14,7,3, -23,-51,0,15,-67,-73,-17,-22,-17,-25,-11,-127,-27,0,-10,9, 
  /* [20][0][][] */ -72,-127,0,-39,-89,-86,-22,-21,-17,-11,-24,-82,-34,-61,4,-59, -91,-44,-83,24,-65,9,-32,-48,3,-51,-27,-64,38,-1,9,-19, -71,-24,-106,-70,-15,-6,-44,-43,-6,-65,-18,-26,61,-46,-39,-26, 
  /* [21][0][][] */ -72,-48,-8,-53,-20,-25,-50,-30,-66,-106,-67,-127,-39,-9,-35,-11, -93,-14,-10,-29,-59,-20,-41,-9,-52,-76,-97,-96,-61,-12,-36,-31, -72,-33,-4,-68,-52,1,-11,-58,-54,-25,-49,-103,-65,3,-8,-8, 
  /* [22][0][][] */ -6,-81,-25,-94,-68,-83,-14,-42,21,-46,-13,-61,-43,-31,-84,-45, -26,-40,-14,-92,-37,-105,-87,-98,25,-90,-19,-51,-47,-17,-81,-43, -11,-100,-51,-88,-64,-46,-16,-73,-63,-127,-24,-65,-38,-19,-99,-50, 
  /* [23][0][][] */ -58,-23,-53,-103,26,-38,-66,-33,1,-18,-7,-2,-5,-14,-5,-3, -41,-55,-23,-109,-38,-98,-58,-82,14,-35,-10,-52,-34,-12,-29,2, -30,-71,-18,-127,-39,-92,-42,-71,-1,-69,14,-122,-28,-23,27,-11, 
  /* [24][0][][] */ -42,30,-17,-63,-70,-18,-10,-26,-49,-15,-17,-75,-33,-2,4,-24, -27,-56,-32,-106,-95,-33,-70,-23,-74,-69,8,-127,5,-9,-7,-3, -29,-45,-125,-112,-46,-5,-64,-52,-30,-58,-14,-46,21,-16,-36,-15, 
  /* [25][0][][] */ -11,-43,-127,-74,-10,68,-48,-31,-48,-54,-15,42,-28,5,-58,-7, -25,-67,-89,-9,-55,2,-47,-52,-13,-10,7,-67,-22,11,-41,2, 8,-51,-46,-19,-78,-20,-19,-44,-37,-7,-1,-82,-5,-2,-65,-9, 
  /* [26][0][][] */ -48,-41,-22,-16,-60,-5,-127,-10,-19,-20,-14,-61,0,4,-5,13, -17,-56,-11,-16,-24,20,-62,-2,-11,-54,-15,-51,-22,-11,34,8, -52,-79,-19,-3,-41,-15,-70,-25,-10,-26,-6,-30,-14,-4,3,-5, 
  /* [27][0][][] */ -33,-51,-56,-38,-33,-9,-63,-23,-20,-45,-2,-127,-7,-6,25,-6, -41,-26,-70,-26,-53,-25,-35,-65,-30,-29,0,-48,-25,-24,16,-13, -23,12,-11,1,2,31,-12,-46,-12,27,-6,-41,4,-32,25,-8, 
  /* [28][0][][] */ -116,-117,-3,-54,-17,-27,-63,-59,-39,-96,32,-85,-32,1,-69,7, -73,-31,-14,-15,-4,3,-81,-37,-45,-127,12,-47,-3,-16,-66,15, -120,-68,-14,-69,23,3,-37,-20,-19,-73,18,-23,-72,-32,-95,-7, 
  /* [29][0][][] */ -79,-101,-84,-42,-36,-25,-15,-108,-6,-17,23,-20,-34,-13,-39,-6, -106,-40,-64,-33,-24,-13,-68,-59,7,-23,0,-33,-38,-20,20,-7, -127,22,-93,-36,39,-10,-38,-29,0,-24,-8,-40,11,-15,34,-13, 
  /* [30][0][][] */ -79,-70,-65,-6,-72,-24,-18,-88,-27,-127,-14,-78,-22,-44,-35,32, -77,-60,-123,-62,-54,-73,-34,-37,12,-37,27,-119,-37,-21,-67,37, -60,-61,-64,-121,-45,-60,-80,-28,-14,-66,-7,-70,-12,-117,-56,28, 
  /* [31][0][][] */ -7,11,-7,-15,19,9,-127,-15,17,-23,-1,-29,6,-5,11,3, -14,3,-10,1,-6,-14,-27,-21,16,-28,0,-37,-18,-10,1,-7, -29,-16,-5,-8,8,1,-8,-12,6,-16,-3,-12,-6,-4,-3,0, 
};
const TfArray<4, int> tensor_dimension12 = { 4, { 32,1,3,16 } };
const TfArray<32, float> quant12_scale = { 32, { 0.015691997483372688, 0.021426578983664513, 0.017949234694242477, 0.012222487479448318, 0.020185884088277817, 0.019648836925625801, 0.021507937461137772, 0.02059406042098999, 0.033976104110479355, 0.011601660400629044, 0.011375652626156807, 0.014086865819990635, 0.032705187797546387, 0.013193865306675434, 0.0054258150048553944, 0.021348012611269951, 0.02932523749768734, 0.014984234236180782, 0.028624990954995155, 0.020885609090328217, 0.011167922988533974, 0.012888938188552856, 0.0068674571812152863, 0.014861064963042736, 0.01178978756070137, 0.01830650307238102, 0.02853090688586235, 0.030915955081582069, 0.021176779642701149, 0.026020638644695282, 0.018171364441514015, 0.060442451387643814, } };
const TfArray<32, int> quant12_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant12 = { (TfLiteFloatArray*)&quant12_scale, (TfLiteIntArray*)&quant12_zero, 0 };
const ALIGN(16) int32_t tensor_data13[32] = { -688, -213, -384, -496, -763, -217, -440, -497, -251, -734, -650, -670, -569, -426, -958, -242, -213, -1074, -340, -383, -455, -704, -586, -240, -456, -181, -506, 34, -431, -70, -397, -279, };
const TfArray<1, int> tensor_dimension13 = { 1, { 32 } };
const TfArray<32, float> quant13_scale = { 32, { 0.0032358064781874418, 0.0044183195568621159, 0.0037012654356658459, 0.0025203677359968424, 0.0041624791920185089, 0.0040517360903322697, 0.0044350964017212391, 0.0042466479353606701, 0.007006125058978796, 0.002392348600551486, 0.0023457440547645092, 0.00290481629781425, 0.0067440527491271496, 0.002720672870054841, 0.0011188433272764087, 0.0044021187350153923, 0.0060470816679298878, 0.0030898603145033121, 0.0059026856906712055, 0.0043067676015198231, 0.0023029085714370012, 0.0026577948592603207, 0.0014161206781864166, 0.0030644619837403297, 0.0024311416782438755, 0.0037749367766082287, 0.0058832848444581032, 0.0063750995323061943, 0.0043668090365827084, 0.0053656487725675106, 0.0037470702081918716, 0.01246368233114481, } };
const TfArray<32, int> quant13_zero = { 32, { 0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 } };
const TfLiteAffineQuantization quant13 = { (TfLiteFloatArray*)&quant13_scale, (TfLiteIntArray*)&quant13_zero, 0 };
const ALIGN(16) int8_t tensor_data14[6*160] = { 
  -61, -52, -22, -14, 27, 8, -1, 6, 19, -9, -19, -7, 26, 0, 15, 1, -13, -25, 8, 3, -10, 38, -11, -31, -9, 1, 91, -9, -15, -22, 52, 15, -38, -28, 5, 32, 51, -16, -31, -19, 26, -3, -19, -38, 19, -21, 40, -30, 8, -46, 30, -12, 2, -27, 10, 4, 32, -10, 44, -33, -26, 43, 59, 12, -42, -1, 18, 31, 68, 0, -52, 18, 41, 9, -68, -59, 41, -10, 7, -36, -33, 40, -36, 19, 2, 29, 8, -60, -25, -34, 72, -52, -81, 55, 27, 36, -9, -19, 38, 26, 24, -4, -8, 34, 54, 27, -7, -49, 53, -8, -12, 1, -9, 15, 39, 27, 4, 4, -8, -15, -17, -18, 23, 7, -66, 33, 52, 26, -9, 6, 43, -3, 86, -4, -9, -58, 35, 10, 45, -4, 11, -31, 4, -19, 26, -30, 26, 19, -16, -1, 0, 11, 19, -7, 0, 9, -29, 65, 17, 6, 
  43, 43, -36, 8, -13, 44, -7, -32, -90, 18, 42, -10, -33, 66, -10, -6, -8, 57, -25, -2, 39, 25, -13, -10, 53, 18, -62, -7, 48, 18, 31, -24, 46, 39, -20, -6, -105, 59, -34, -4, -66, -17, 22, 41, -30, 48, -6, 28, -49, -29, -8, -23, -20, 35, -10, -10, -38, 38, -79, -31, -20, -74, 20, 17, 54, 44, -15, -22, -127, 38, -54, -4, -87, -71, 16, 10, -17, 25, 2, 20, -26, -44, -5, -23, -7, 0, -9, -10, 20, 28, -51, -19, -16, -105, 21, -9, 34, 64, -46, -17, -99, 23, -12, -63, -96, -40, 1, -1, -20, 28, 9, 36, -15, -44, 10, -14, 0, -18, 18, -7, 21, 25, -34, 4, 18, -74, 16, -18, 39, 37, -24, 4, -40, 60, -31, -14, -79, -52, -5, 22, -23, 14, -4, 18, -38, -31, 9, 2, 26, -4, 14, -5, 4, 22, 26, -20, 5, -26, 15, -38, 
  12, -34, -12, 12, 8, -37, 18, 41, 19, -18, -23, 13, -13, -36, -1, 74, -6, -14, -36, -38, -24, 27, 19, -4, -14, -33, -19, 15, -15, 16, -76, -20, 18, -52, -1, -3, -48, -54, 1, 59, 35, -7, -8, -64, -38, 14, -6, -7, 4, -3, 0, -27, 1, -6, -11, 7, -30, -56, -58, 46, -22, 79, -71, 11, -12, -52, 2, -10, -16, -48, -5, 18, 66, -24, 46, -37, -35, 3, -3, -36, 3, 4, -22, -37, -11, -29, 6, 30, -3, -28, -55, 26, 24, 75, -41, -9, 17, -23, 14, -20, -53, -47, 14, -24, 43, 0, 45, -21, -43, -5, -5, -40, 2, -49, -14, -53, -7, -3, -19, -7, 12, -22, -63, 29, -5, 73, -16, 11, -20, -26, 25, -1, -33, -13, -6, 63, 40, -9, 44, 2, 2, -6, -14, -3, -37, 10, -16, -5, 13, 21, 7, -2, 24, -27, -48, 26, -40, 80, 19, 46, 
  -7, 32, -8, -28, -5, -13, -45, -92, -13, -4, 48, 42, 48, -36, -6, 1, -20, -17, 34, 40, -18, -27, 26, -13, -25, -4, 81, 10, -3, 10, -18, 2, -43, 42, -10, 9, 98, 7, 30, -57, -66, -18, -21, 108, -5, -17, -11, 8, -31, 2, -7, 72, -1, -10, 38, -15, 44, 28, 25, 6, 35, -36, -10, 12, -41, 24, 4, 3, 13, 10, 26, -47, -78, -10, -63, 53, 40, 2, -5, 31, 16, 5, 51, 33, 4, 33, 10, -27, 10, 17, 57, -11, 51, -7, -17, 16, -3, 9, -59, 26, 64, 19, -11, -24, -27, 28, -69, 22, 0, -16, 10, -10, -24, 49, 51, 17, -1, 11, -25, -1, -18, 12, 67, -3, -9, -29, 4, -11, 18, -18, -26, -30, 73, 32, 17, -17, -21, 6, -56, -27, 23, 19, 13, -11, 9, -5, -39, 7, -8, -5, -10, -1, -27, -2, 55, 7, 60, -34, -13, 12, 
  -15, 18, 17, 3, 0, -6, 3, 58, 71, 1, -28, -14, -21, 15, 4, -28, 46, 6, 39, 3, -17, -23, -16, 40, 9, 19, -21, -21, -36, -11, 31, 7, 4, 17, 4, -10, 50, -4, 5, -51, 34, 17, 8, -6, 25, -15, 13, 7, 31, 25, 35, -39, -3, -11, -9, -8, -17, 18, 100, 6, -75, 20, 33, -23, 27, 32, -9, 15, 68, 24, 7, -6, 10, 34, 28, 33, -19, -7, 12, -2, 15, 6, 40, 14, 8, -28, 20, 63, -10, 11, 39, 19, -36, 19, 37, 10, -9, -2, 24, 8, 81, 28, 8, 26, 9, -12, 4, 32, 9, -6, 13, -12, 58, -8, -31, 1, 14, 17, 17, 13, 1, -4, 25, -22, -4, -21, -14, 24, -37, 3, 18, 21, -57, -44, -4, 53, 40, 12, -2, 14, -8, -6, -5, 0, 24, -8, 53, -12, 6, 13, -13, -4, 16, 9, -35, -34, -33, -47, 16, -8, 
  24, -14, 28, 2, -9, 8, 6, 27, -18, -1, -13, -16, -6, -8, -19, -51, 15, -15, -17, -23, 28, -47, -16, 14, -17, -17, -87, 8, 25, -11, -13, 20, -4, -14, 20, -6, -56, -11, 29, 80, 12, 30, 12, -29, 22, 11, -8, -9, 44, 48, -40, 25, 14, 21, -37, 17, 11, -25, -19, 0, 96, -17, -40, -20, 0, -58, 1, 0, -14, -10, 64, 32, 48, 62, 17, 9, -7, -19, 0, 14, 13, -1, -27, -15, -3, 0, -19, 4, 0, -2, -24, 22, 76, -37, -32, -52, -3, -12, 27, -18, 3, -16, 6, 43, -2, 12, 28, 3, 0, 7, 2, 23, 4, 52, -56, 20, -12, -19, 2, 10, 8, 6, -22, 15, 73, -1, -40, -27, 17, -19, -47, -8, -24, -15, 37, -22, -17, 24, -18, 9, -9, 16, -7, -4, 29, 54, -24, -12, -5, -15, -8, -15, -30, 4, 12, 14, 39, -39, -51, -41, 
};
const TfArray<2, int> tensor_dimension14 = { 2, { 6,160 } };
const TfArray<1, float> quant14_scale = { 1, { 0.023859884589910507, } };
const TfArray<1, int> quant14_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant14 = { (TfLiteFloatArray*)&quant14_scale, (TfLiteIntArray*)&quant14_zero, 0 };
const ALIGN(16) int32_t tensor_data15[6] = { 33, 159, -210, 34, 54, -69, };
const TfArray<1, int> tensor_dimension15 = { 1, { 6 } };
const TfArray<1, float> quant15_scale = { 1, { 0.0030075991526246071, } };
const TfArray<1, int> quant15_zero = { 1, { 0 } };
const TfLiteAffineQuantization quant15 = { (TfLiteFloatArray*)&quant15_scale, (TfLiteIntArray*)&quant15_zero, 0 };
const TfArray<4, int> tensor_dimension16 = { 4, { 1,1,39,13 } };
const TfArray<1, float> quant16_scale = { 1, { 0.053833801299333572, } };
const TfArray<1, int> quant16_zero = { 1, { 1 } };
const TfLiteAffineQuantization quant16 = { (TfLiteFloatArray*)&quant16_scale, (TfLiteIntArray*)&quant16_zero, 0 };
const TfArray<4, int> tensor_dimension17 = { 4, { 1,1,39,8 } };
const TfArray<1, float> quant17_scale = { 1, { 0.23068812489509583, } };
const TfArray<1, int> quant17_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant17 = { (TfLiteFloatArray*)&quant17_scale, (TfLiteIntArray*)&quant17_zero, 0 };
const TfArray<4, int> tensor_dimension18 = { 4, { 1,39,1,8 } };
const TfArray<1, float> quant18_scale = { 1, { 0.23068812489509583, } };
const TfArray<1, int> quant18_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant18 = { (TfLiteFloatArray*)&quant18_scale, (TfLiteIntArray*)&quant18_zero, 0 };
const TfArray<4, int> tensor_dimension19 = { 4, { 1,20,1,8 } };
const TfArray<1, float> quant19_scale = { 1, { 0.23068812489509583, } };
const TfArray<1, int> quant19_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant19 = { (TfLiteFloatArray*)&quant19_scale, (TfLiteIntArray*)&quant19_zero, 0 };
const TfArray<4, int> tensor_dimension20 = { 4, { 1,1,20,8 } };
const TfArray<1, float> quant20_scale = { 1, { 0.23068812489509583, } };
const TfArray<1, int> quant20_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant20 = { (TfLiteFloatArray*)&quant20_scale, (TfLiteIntArray*)&quant20_zero, 0 };
const TfArray<4, int> tensor_dimension21 = { 4, { 1,1,20,16 } };
const TfArray<1, float> quant21_scale = { 1, { 0.20620742440223694, } };
const TfArray<1, int> quant21_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant21 = { (TfLiteFloatArray*)&quant21_scale, (TfLiteIntArray*)&quant21_zero, 0 };
const TfArray<4, int> tensor_dimension22 = { 4, { 1,20,1,16 } };
const TfArray<1, float> quant22_scale = { 1, { 0.20620742440223694, } };
const TfArray<1, int> quant22_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant22 = { (TfLiteFloatArray*)&quant22_scale, (TfLiteIntArray*)&quant22_zero, 0 };
const TfArray<4, int> tensor_dimension23 = { 4, { 1,10,1,16 } };
const TfArray<1, float> quant23_scale = { 1, { 0.20620742440223694, } };
const TfArray<1, int> quant23_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant23 = { (TfLiteFloatArray*)&quant23_scale, (TfLiteIntArray*)&quant23_zero, 0 };
const TfArray<4, int> tensor_dimension24 = { 4, { 1,1,10,16 } };
const TfArray<1, float> quant24_scale = { 1, { 0.20620742440223694, } };
const TfArray<1, int> quant24_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant24 = { (TfLiteFloatArray*)&quant24_scale, (TfLiteIntArray*)&quant24_zero, 0 };
const TfArray<4, int> tensor_dimension25 = { 4, { 1,1,10,32 } };
const TfArray<1, float> quant25_scale = { 1, { 0.12605254352092743, } };
const TfArray<1, int> quant25_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant25 = { (TfLiteFloatArray*)&quant25_scale, (TfLiteIntArray*)&quant25_zero, 0 };
const TfArray<4, int> tensor_dimension26 = { 4, { 1,10,1,32 } };
const TfArray<1, float> quant26_scale = { 1, { 0.12605254352092743, } };
const TfArray<1, int> quant26_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant26 = { (TfLiteFloatArray*)&quant26_scale, (TfLiteIntArray*)&quant26_zero, 0 };
const TfArray<4, int> tensor_dimension27 = { 4, { 1,5,1,32 } };
const TfArray<1, float> quant27_scale = { 1, { 0.12605254352092743, } };
const TfArray<1, int> quant27_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant27 = { (TfLiteFloatArray*)&quant27_scale, (TfLiteIntArray*)&quant27_zero, 0 };
const TfArray<2, int> tensor_dimension28 = { 2, { 1,160 } };
const TfArray<1, float> quant28_scale = { 1, { 0.12605254352092743, } };
const TfArray<1, int> quant28_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant28 = { (TfLiteFloatArray*)&quant28_scale, (TfLiteIntArray*)&quant28_zero, 0 };
const TfArray<2, int> tensor_dimension29 = { 2, { 1,6 } };
const TfArray<1, float> quant29_scale = { 1, { 0.59173339605331421, } };
const TfArray<1, int> quant29_zero = { 1, { -31 } };
const TfLiteAffineQuantization quant29 = { (TfLiteFloatArray*)&quant29_scale, (TfLiteIntArray*)&quant29_zero, 0 };
const TfArray<2, int> tensor_dimension30 = { 2, { 1,6 } };
const TfArray<1, float> quant30_scale = { 1, { 0.00390625, } };
const TfArray<1, int> quant30_zero = { 1, { -128 } };
const TfLiteAffineQuantization quant30 = { (TfLiteFloatArray*)&quant30_scale, (TfLiteIntArray*)&quant30_zero, 0 };
const TfLiteReshapeParams opdata0 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs0 = { 2, { 0,1 } };
const TfArray<1, int> outputs0 = { 1, { 16 } };
const TfLiteConvParams opdata1 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs1 = { 3, { 16,8,9 } };
const TfArray<1, int> outputs1 = { 1, { 17 } };
const TfLiteReshapeParams opdata2 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs2 = { 2, { 17,2 } };
const TfArray<1, int> outputs2 = { 1, { 18 } };
const TfLitePoolParams opdata3 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs3 = { 1, { 18 } };
const TfArray<1, int> outputs3 = { 1, { 19 } };
const TfLiteReshapeParams opdata4 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs4 = { 2, { 19,3 } };
const TfArray<1, int> outputs4 = { 1, { 20 } };
const TfLiteConvParams opdata5 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs5 = { 3, { 20,10,11 } };
const TfArray<1, int> outputs5 = { 1, { 21 } };
const TfLiteReshapeParams opdata6 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs6 = { 2, { 21,4 } };
const TfArray<1, int> outputs6 = { 1, { 22 } };
const TfLitePoolParams opdata7 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs7 = { 1, { 22 } };
const TfArray<1, int> outputs7 = { 1, { 23 } };
const TfLiteReshapeParams opdata8 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs8 = { 2, { 23,5 } };
const TfArray<1, int> outputs8 = { 1, { 24 } };
const TfLiteConvParams opdata9 = { kTfLitePaddingSame, 1,1, kTfLiteActRelu, 1,1 };
const TfArray<3, int> inputs9 = { 3, { 24,12,13 } };
const TfArray<1, int> outputs9 = { 1, { 25 } };
const TfLiteReshapeParams opdata10 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs10 = { 2, { 25,6 } };
const TfArray<1, int> outputs10 = { 1, { 26 } };
const TfLitePoolParams opdata11 = { kTfLitePaddingSame, 1,2, 1,2, kTfLiteActNone, { { 0,0, 0, 0 } } };
const TfArray<1, int> inputs11 = { 1, { 26 } };
const TfArray<1, int> outputs11 = { 1, { 27 } };
const TfLiteReshapeParams opdata12 = { { 0, 0, 0, 0, 0, 0, 0, 0, }, 0 };
const TfArray<2, int> inputs12 = { 2, { 27,7 } };
const TfArray<1, int> outputs12 = { 1, { 28 } };
const TfLiteFullyConnectedParams opdata13 = { kTfLiteActNone, kTfLiteFullyConnectedWeightsFormatDefault, false, false };
const TfArray<3, int> inputs13 = { 3, { 28,14,15 } };
const TfArray<1, int> outputs13 = { 1, { 29 } };
const TfLiteSoftmaxParams opdata14 = { 1 };
const TfArray<1, int> inputs14 = { 1, { 29 } };
const TfArray<1, int> outputs14 = { 1, { 30 } };
const TensorInfo_t tensorData[] = {
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 512, (TfLiteIntArray*)&tensor_dimension0, 507, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant0))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data1, (TfLiteIntArray*)&tensor_dimension1, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data2, (TfLiteIntArray*)&tensor_dimension2, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data3, (TfLiteIntArray*)&tensor_dimension3, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data4, (TfLiteIntArray*)&tensor_dimension4, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data5, (TfLiteIntArray*)&tensor_dimension5, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data6, (TfLiteIntArray*)&tensor_dimension6, 16, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data7, (TfLiteIntArray*)&tensor_dimension7, 8, {kTfLiteNoQuantization, nullptr}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data8, (TfLiteIntArray*)&tensor_dimension8, 312, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant8))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data9, (TfLiteIntArray*)&tensor_dimension9, 32, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant9))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data10, (TfLiteIntArray*)&tensor_dimension10, 384, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant10))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data11, (TfLiteIntArray*)&tensor_dimension11, 64, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant11))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data12, (TfLiteIntArray*)&tensor_dimension12, 1536, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant12))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data13, (TfLiteIntArray*)&tensor_dimension13, 128, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant13))}, },
  { kTfLiteMmapRo, kTfLiteInt8, (void*)tensor_data14, (TfLiteIntArray*)&tensor_dimension14, 960, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant14))}, },
  { kTfLiteMmapRo, kTfLiteInt32, (void*)tensor_data15, (TfLiteIntArray*)&tensor_dimension15, 24, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant15))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension16, 507, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant16))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 512, (TfLiteIntArray*)&tensor_dimension17, 312, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant17))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension18, 312, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant18))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 320, (TfLiteIntArray*)&tensor_dimension19, 160, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant19))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension20, 160, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant20))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 320, (TfLiteIntArray*)&tensor_dimension21, 320, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant21))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension22, 320, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant22))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 320, (TfLiteIntArray*)&tensor_dimension23, 160, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant23))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 640, (TfLiteIntArray*)&tensor_dimension24, 160, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant24))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 320, (TfLiteIntArray*)&tensor_dimension25, 320, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant25))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension26, 320, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant26))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 320, (TfLiteIntArray*)&tensor_dimension27, 160, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant27))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension28, 160, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant28))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 160, (TfLiteIntArray*)&tensor_dimension29, 6, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant29))}, },
  { kTfLiteArenaRw, kTfLiteInt8, tensor_arena + 0, (TfLiteIntArray*)&tensor_dimension30, 6, {kTfLiteAffineQuantization, const_cast<void*>(static_cast<const void*>(&quant30))}, },
};const NodeInfo_t nodeData[] = {
  { (TfLiteIntArray*)&inputs0, (TfLiteIntArray*)&outputs0, const_cast<void*>(static_cast<const void*>(&opdata0)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs1, (TfLiteIntArray*)&outputs1, const_cast<void*>(static_cast<const void*>(&opdata1)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs2, (TfLiteIntArray*)&outputs2, const_cast<void*>(static_cast<const void*>(&opdata2)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs3, (TfLiteIntArray*)&outputs3, const_cast<void*>(static_cast<const void*>(&opdata3)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs4, (TfLiteIntArray*)&outputs4, const_cast<void*>(static_cast<const void*>(&opdata4)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs5, (TfLiteIntArray*)&outputs5, const_cast<void*>(static_cast<const void*>(&opdata5)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs6, (TfLiteIntArray*)&outputs6, const_cast<void*>(static_cast<const void*>(&opdata6)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs7, (TfLiteIntArray*)&outputs7, const_cast<void*>(static_cast<const void*>(&opdata7)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs8, (TfLiteIntArray*)&outputs8, const_cast<void*>(static_cast<const void*>(&opdata8)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs9, (TfLiteIntArray*)&outputs9, const_cast<void*>(static_cast<const void*>(&opdata9)), OP_CONV_2D, },
  { (TfLiteIntArray*)&inputs10, (TfLiteIntArray*)&outputs10, const_cast<void*>(static_cast<const void*>(&opdata10)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs11, (TfLiteIntArray*)&outputs11, const_cast<void*>(static_cast<const void*>(&opdata11)), OP_MAX_POOL_2D, },
  { (TfLiteIntArray*)&inputs12, (TfLiteIntArray*)&outputs12, const_cast<void*>(static_cast<const void*>(&opdata12)), OP_RESHAPE, },
  { (TfLiteIntArray*)&inputs13, (TfLiteIntArray*)&outputs13, const_cast<void*>(static_cast<const void*>(&opdata13)), OP_FULLY_CONNECTED, },
  { (TfLiteIntArray*)&inputs14, (TfLiteIntArray*)&outputs14, const_cast<void*>(static_cast<const void*>(&opdata14)), OP_SOFTMAX, },
};

static void init_tflite_tensor(size_t i, TfLiteTensor *tensor) {
  tensor->type = tensorData[i].type;
  tensor->is_variable = 0;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  tensor->allocation_type = tensorData[i].allocation_type;
#else
  tensor->allocation_type = (tensor_arena <= tensorData[i].data && tensorData[i].data < tensor_arena + kTensorArenaSize) ? kTfLiteArenaRw : kTfLiteMmapRo;
#endif
  tensor->bytes = tensorData[i].bytes;
  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  if(tensor->allocation_type == kTfLiteArenaRw){
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
      tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
  tensor->quantization = tensorData[i].quantization;
  if (tensor->quantization.type == kTfLiteAffineQuantization) {
    TfLiteAffineQuantization const* quant = ((TfLiteAffineQuantization const*)(tensorData[i].quantization.params));
    tensor->params.scale = quant->scale->data[0];
    tensor->params.zero_point = quant->zero_point->data[0];
  }

}

static void init_tflite_eval_tensor(int i, TfLiteEvalTensor *tensor) {
  if (i < 0) {
    tensor->data.data = nullptr;
    tensor->dims = nullptr;
    return;
  }

  tensor->type = tensorData[i].type;

  tensor->dims = tensorData[i].dims;

#if defined(EI_CLASSIFIER_ALLOCATION_HEAP)
  auto allocation_type = tensorData[i].allocation_type;
  if(allocation_type == kTfLiteArenaRw) {
    uint8_t* start = (uint8_t*) ((uintptr_t)tensorData[i].data + (uintptr_t) tensor_arena);

    tensor->data.data =  start;
  }
  else {
    tensor->data.data = tensorData[i].data;
  }
#else
  tensor->data.data = tensorData[i].data;
#endif // EI_CLASSIFIER_ALLOCATION_HEAP
}

static void* overflow_buffers[EI_MAX_OVERFLOW_BUFFER_COUNT];
static size_t overflow_buffers_ix = 0;
static void * AllocatePersistentBuffer(struct TfLiteContext* ctx,
                                       size_t bytes) {
  void *ptr;
  if (current_location - bytes < tensor_boundary) {
    if (overflow_buffers_ix > EI_MAX_OVERFLOW_BUFFER_COUNT - 1) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d, does not fit in tensor arena and reached EI_MAX_OVERFLOW_BUFFER_COUNT\n",
        (int)bytes);
      return NULL;
    }

    // OK, this will look super weird, but.... we have CMSIS-NN buffers which
    // we cannot calculate beforehand easily.
    ptr = ei_calloc(bytes, 1);
    if (ptr == NULL) {
      ei_printf("ERR: Failed to allocate persistent buffer of size %d\n", (int)bytes);
      return NULL;
    }
    overflow_buffers[overflow_buffers_ix++] = ptr;
    return ptr;
  }

  current_location -= bytes;

  ptr = current_location;
  memset(ptr, 0, bytes);

  return ptr;
}
typedef struct {
  size_t bytes;
  void *ptr;
} scratch_buffer_t;
static scratch_buffer_t scratch_buffers[EI_MAX_SCRATCH_BUFFER_COUNT];
static size_t scratch_buffers_ix = 0;

static TfLiteStatus RequestScratchBufferInArena(struct TfLiteContext* ctx, size_t bytes,
                                                int* buffer_idx) {
  if (scratch_buffers_ix > EI_MAX_SCRATCH_BUFFER_COUNT - 1) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d, reached EI_MAX_SCRATCH_BUFFER_COUNT\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffer_t b;
  b.bytes = bytes;

  b.ptr = AllocatePersistentBuffer(ctx, b.bytes);
  if (!b.ptr) {
    ei_printf("ERR: Failed to allocate scratch buffer of size %d\n",
      (int)bytes);
    return kTfLiteError;
  }

  scratch_buffers[scratch_buffers_ix] = b;
  *buffer_idx = scratch_buffers_ix;

  scratch_buffers_ix++;

  return kTfLiteOk;
}

static void* GetScratchBuffer(struct TfLiteContext* ctx, int buffer_idx) {
  if (buffer_idx > (int)scratch_buffers_ix) {
    return NULL;
  }
  return scratch_buffers[buffer_idx].ptr;
}

static const uint16_t TENSOR_IX_UNUSED = 0x7FFF;

static void ResetTensors() {
  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    tflTensors[ix].index = TENSOR_IX_UNUSED;
  }
  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    tflEvalTensors[ix].index = TENSOR_IX_UNUSED;
  }
}

static TfLiteTensor* GetTensor(const struct TfLiteContext* context,
                               int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_TENSOR_COUNT; ix++) {
    // already used? OK!
    if (tflTensors[ix].index == tensor_idx) {
      return &tflTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_tensor(tensor_idx, &tflTensors[ix].tensor);
      tflTensors[ix].index = tensor_idx;
      return &tflTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_TENSOR_COUNT (%d)\n", MAX_TFL_TENSOR_COUNT);
  return nullptr;
}

static TfLiteEvalTensor* GetEvalTensor(const struct TfLiteContext* context,
                                       int tensor_idx) {

  for (size_t ix = 0; ix < MAX_TFL_EVAL_COUNT; ix++) {
    // already used? OK!
    if (tflEvalTensors[ix].index == tensor_idx) {
      return &tflEvalTensors[ix].tensor;
    }
    // passed all the ones we've used, so end of the list?
    if (tflEvalTensors[ix].index == TENSOR_IX_UNUSED) {
      // init the tensor
      init_tflite_eval_tensor(tensor_idx, &tflEvalTensors[ix].tensor);
      tflEvalTensors[ix].index = tensor_idx;
      return &tflEvalTensors[ix].tensor;
    }
  }

  ei_printf("ERR: GetTensor called beyond MAX_TFL_EVAL_COUNT (%d)\n", (int)MAX_TFL_EVAL_COUNT);
  return nullptr;
}

} // namespace

TfLiteStatus tflite_learn_11_init( void*(*alloc_fnc)(size_t,size_t) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  tensor_arena = (uint8_t*) alloc_fnc(16, kTensorArenaSize);
  if (!tensor_arena) {
    ei_printf("ERR: failed to allocate tensor arena\n");
    return kTfLiteError;
  }
#else
  memset(tensor_arena, 0, kTensorArenaSize);
#endif
  tensor_boundary = tensor_arena;
  current_location = tensor_arena + kTensorArenaSize;
  ctx.AllocatePersistentBuffer = &AllocatePersistentBuffer;
  ctx.RequestScratchBufferInArena = &RequestScratchBufferInArena;
  ctx.GetScratchBuffer = &GetScratchBuffer;
  ctx.GetTensor = &GetTensor;
  ctx.GetEvalTensor = &GetEvalTensor;
  ctx.tensors_size = 31;
  for (size_t i = 0; i < 31; ++i) {
    TfLiteTensor tensor;
    init_tflite_tensor(i, &tensor);
    if (tensor.allocation_type == kTfLiteArenaRw) {
      auto data_end_ptr = (uint8_t*)tensor.data.data + tensorData[i].bytes;
      if (data_end_ptr > tensor_boundary) {
        tensor_boundary = data_end_ptr;
      }
    }
  }
  if (tensor_boundary > current_location /* end of arena size */) {
    ei_printf("ERR: tensor arena is too small, does not fit model - even without scratch buffers\n");
    return kTfLiteError;
  }
  registrations[OP_RESHAPE] = Register_RESHAPE();
  registrations[OP_CONV_2D] = Register_CONV_2D();
  registrations[OP_MAX_POOL_2D] = Register_MAX_POOL_2D();
  registrations[OP_FULLY_CONNECTED] = Register_FULLY_CONNECTED();
  registrations[OP_SOFTMAX] = Register_SOFTMAX();

  for (size_t i = 0; i < 15; ++i) {
    tflNodes[i].inputs = nodeData[i].inputs;
    tflNodes[i].outputs = nodeData[i].outputs;
    tflNodes[i].builtin_data = nodeData[i].builtin_data;
tflNodes[i].custom_initial_data = nullptr;
      tflNodes[i].custom_initial_data_size = 0;
if (registrations[nodeData[i].used_op_index].init) {
      tflNodes[i].user_data = registrations[nodeData[i].used_op_index].init(&ctx, (const char*)tflNodes[i].builtin_data, 0);
    }
  }
  for (size_t i = 0; i < 15; ++i) {
    if (registrations[nodeData[i].used_op_index].prepare) {
      ResetTensors();

      TfLiteStatus status = registrations[nodeData[i].used_op_index].prepare(&ctx, &tflNodes[i]);
      if (status != kTfLiteOk) {
        return status;
      }
    }
  }
  return kTfLiteOk;
}

static const int inTensorIndices[] = {
  0, 
};
TfLiteStatus tflite_learn_11_input(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(inTensorIndices[index], tensor);
  return kTfLiteOk;
}

static const int outTensorIndices[] = {
  30, 
};
TfLiteStatus tflite_learn_11_output(int index, TfLiteTensor *tensor) {
  init_tflite_tensor(outTensorIndices[index], tensor);
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_11_invoke() {
  for (size_t i = 0; i < 15; ++i) {
    ResetTensors();

    TfLiteStatus status = registrations[nodeData[i].used_op_index].invoke(&ctx, &tflNodes[i]);

#if EI_CLASSIFIER_PRINT_STATE
    ei_printf("layer %lu\n", i);
    ei_printf("    inputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].inputs->size; ix++) {
      auto d = tensorData[tflNodes[i].inputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");

    ei_printf("    outputs:\n");
    for (size_t ix = 0; ix < tflNodes[i].outputs->size; ix++) {
      auto d = tensorData[tflNodes[i].outputs->data[ix]];

      size_t data_ptr = (size_t)d.data;

      if (d.allocation_type == kTfLiteArenaRw) {
        data_ptr = (size_t)tensor_arena + data_ptr;
      }

      if (d.type == TfLiteType::kTfLiteInt8) {
        int8_t* data = (int8_t*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes; jx++) {
          ei_printf("%d ", data[jx]);
        }
      }
      else {
        float* data = (float*)data_ptr;
        ei_printf("        %lu (%zu bytes, ptr=%p, alloc_type=%d, type=%d): ", ix, d.bytes, data, (int)d.allocation_type, (int)d.type);
        for (size_t jx = 0; jx < d.bytes / 4; jx++) {
          ei_printf("%f ", data[jx]);
        }
      }
      ei_printf("\n");
    }
    ei_printf("\n");
#endif // EI_CLASSIFIER_PRINT_STATE

    if (status != kTfLiteOk) {
      return status;
    }
  }
  return kTfLiteOk;
}

TfLiteStatus tflite_learn_11_reset( void (*free_fnc)(void* ptr) ) {
#ifdef EI_CLASSIFIER_ALLOCATION_HEAP
  free_fnc(tensor_arena);
#endif

  // scratch buffers are allocated within the arena, so just reset the counter so memory can be reused
  scratch_buffers_ix = 0;

  // overflow buffers are on the heap, so free them first
  for (size_t ix = 0; ix < overflow_buffers_ix; ix++) {
    ei_free(overflow_buffers[ix]);
  }
  overflow_buffers_ix = 0;
  return kTfLiteOk;
}
